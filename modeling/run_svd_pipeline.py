"""
SVD íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""
import logging
from pathlib import Path
from models.svd import SVDRecommenderPipeline, ModelConfig
from utils.data_integration import DataIntegrator

# Firebase ì´ˆê¸°í™”
from user_system.firebase_config import setup_firebase_config

# Logger ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def main():
    logger.info("ğŸš€ SVD ì¶”ì²œ ì‹œìŠ¤í…œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    
    # YAML íŒŒì¼ì—ì„œ ëª¨ë¸ ì„¤ì • ë¡œë“œ
    config = ModelConfig.from_yaml()
    
    # ë°ì´í„° ë¡œë“œ (configì—ì„œ í†µí•© ë°ì´í„° ì‚¬ìš© ì—¬ë¶€ í™•ì¸)
    if getattr(config, 'use_integrated_data', True): # ì‚¬ìš©í•  ë–„ True
        logger.info("ğŸ“Š Firebase í†µí•© ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤...")
        
        # Firebase ì´ˆê¸°í™”
        logger.info("ğŸ”¥ Firebaseë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘...")
        firebase_available = setup_firebase_config()
        if not firebase_available:
            logger.error("âŒ Firebase ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            logger.info("ğŸ“Š ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤...")
        else:
            logger.info("âœ… Firebase ì´ˆê¸°í™” ì™„ë£Œ!")
            integrator = DataIntegrator()
            
            # 1. ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
            logger.info("ğŸ“¥ ê¸°ì¡´ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘...")
            original_data = integrator.load_original_data()
            logger.info(f"  - ê¸°ì¡´ ë°ì´í„°: {len(original_data):,}ê°œ í‰ì ")
            
            # 2. Firebase ë°ì´í„° ë¡œë“œ
            logger.info("ğŸ“¥ Firebase ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘...")
            firebase_data = integrator.load_firebase_data()
            logger.info(f"  - Firebase ë°ì´í„°: {len(firebase_data):,}ê°œ í‰ì ")
            
            # 3. ë°ì´í„° í†µí•©
            logger.info("ğŸ”— ë°ì´í„°ë¥¼ í†µí•©í•˜ëŠ” ì¤‘...")
            integrated_data = integrator.integrate_data(original_data, firebase_data)
            logger.info(f"  - í†µí•©ëœ ë°ì´í„°: {len(integrated_data):,}ê°œ í‰ì ")
            
            # 4. ë°ì´í„° í•„í„°ë§ (ê¸°ì¡´ ëª¨ë¸ì˜ í•„í„°ë§ ì„¤ì • ì‚¬ìš©)
            logger.info("ğŸ” ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ëŠ” ì¤‘...")
            logger.info(f"  - í•„í„°ë§ ì¡°ê±´: ì‚¬ìš©ìë‹¹ ìµœì†Œ {config.min_user_ratings}ê°œ, ì˜í™”ë‹¹ ìµœì†Œ {config.min_movie_ratings}ê°œ")
            
            filtered_data = integrator.filter_data(
                integrated_data, 
                min_user_ratings=config.min_user_ratings,
                min_movie_ratings=config.min_movie_ratings
            )
            
            # 5. í†µê³„ ì •ë³´ ì¶œë ¥
            stats = integrator.get_data_statistics(filtered_data)
            logger.info("="*60)
            logger.info("ğŸ“ˆ Firebase í†µí•© ë°ì´í„° í†µê³„")
            logger.info("="*60)
            logger.info(f"  - ì´ í‰ì  ìˆ˜: {stats['total_ratings']:,}")
            logger.info(f"  - ê³ ìœ  ì‚¬ìš©ì: {stats['unique_users']:,}")
            logger.info(f"  - ê³ ìœ  ì˜í™”: {stats['unique_movies']:,}")
            logger.info(f"  - í‰ê·  í‰ì : {stats['avg_rating']:.2f}")
            
            # í‰ì  ë¶„í¬ ì¶œë ¥
            if stats['rating_distribution']:
                logger.info("  - í‰ì  ë¶„í¬:")
                for rating, count in sorted(stats['rating_distribution'].items()):
                    logger.info(f"    {rating}ì : {count:,}ê°œ")
            
            # í†µí•©ëœ ë°ì´í„°ë¥¼ configì— ì„¤ì •
            config.df_ratings = filtered_data
            logger.info("âœ… í†µí•©ëœ ë°ì´í„°ë¡œ ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        logger.info("ğŸ“Š ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤...")
    
    # íŒŒì´í”„ë¼ì¸ ìƒì„± ë° ì „ì²´ ì‹¤í–‰
    pipeline = SVDRecommenderPipeline(config)
    metrics = pipeline.run_full_pipeline()
    
    # ê²°ê³¼ ì¶œë ¥
    logger.info("=" * 60)
    logger.info("ğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼:")
    logger.info(str(metrics))
    
    # ëª¨ë¸ ì €ì¥
    model_dir = Path(__file__).parent / 'models' / 'pkls'
    model_path = model_dir / 'trained_svd_pipeline.pkl'
    pipeline.save_model(str(model_path))
    
    # ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
    logger.info("=" * 60)
    logger.info("ğŸ”„ ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸...")
    loaded_pipeline = SVDRecommenderPipeline.load_model(str(model_path))
    
    # ì¶”ì²œ í…ŒìŠ¤íŠ¸
    logger.info("=" * 60)
    logger.info("ğŸ¬ ì¶”ì²œ í…ŒìŠ¤íŠ¸...")
    
    from data_scraping.common.data_loader import load_movie_data
    df_movies = load_movie_data()
    
    # ì²« ë²ˆì§¸ ì‚¬ìš©ìì—ê²Œ ì¶”ì²œ
    user_id = loaded_pipeline.df_filtered['user_id'].iloc[0]
    logger.info(f"ì‚¬ìš©ì ID: {user_id}")
    
    top_watched, recommendations = loaded_pipeline.recommend_for_user(
        user_id, df_movies, n=5
    )
    
    logger.info("âœ¨ ì¶”ì²œ ì˜í™” (ì˜ˆìƒ í‰ì  ë†’ì€ ìˆœ):")
    for idx, row in recommendations.iterrows():
        logger.info(f"{idx+1}. {row.get('title', 'N/A')} (ì˜ˆì¸¡ í‰ì : {row['predicted_rating']:.2f})")
        logger.info(f"   ì¥ë¥´: {row.get('genre', 'N/A')}, ì—°ë„: {row.get('year', 'N/A')}")
    
    logger.info("ğŸ¬ ìì£¼ ë³¸ ì˜í™” (ë†’ì€ í‰ì  ìˆœ):")
    for idx, row in top_watched.iterrows():
        logger.info(f"{idx+1}. {row['movie_title']} (í‰ì : {row['rating']:.1f})")
    
    logger.info("=" * 60)
    logger.info("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    main()

