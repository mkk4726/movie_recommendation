"""
SVD ê¸°ë°˜ ì˜í™” ì¶”ì²œ ì‹œìŠ¤í…œ íŒŒì´í”„ë¼ì¸
"""
import pickle
import logging
import yaml
from pathlib import Path
from typing import Tuple, Optional
from dataclasses import dataclass

import pandas as pd
from surprise import SVD, Dataset, Reader, accuracy
from surprise.model_selection import train_test_split

import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from data_scraping.common.data_loader import load_ratings_data, load_movie_data
from modeling.utils.data import filter_by_min_counts
from modeling.utils.file_utils import format_file_size

# Logger ì„¤ì •
logger = logging.getLogger(__name__)


@dataclass
class ModelConfig:
    """SVD ëª¨ë¸ ì„¤ì •"""
    n_factors: int = 50
    n_epochs: int = 20
    lr_all: float = 0.005
    reg_all: float = 0.02
    random_state: int = 42
    verbose: bool = True
    test_size: float = 0.2
    min_user_ratings: int = 30
    min_movie_ratings: int = 10
    rating_scale: Tuple[float, float] = (0.5, 5.0)
    
    # ë°ì´í„° í†µí•© ì„¤ì •
    use_integrated_data: bool = False
    
    @classmethod
    def from_yaml(cls, yaml_path: Optional[str] = None) -> 'ModelConfig':
        """
        YAML íŒŒì¼ì—ì„œ ì„¤ì •ì„ ë¡œë“œí•˜ì—¬ ModelConfig ê°ì²´ ìƒì„±
        
        Args:
            yaml_path: YAML íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©)
            
        Returns:
            ModelConfig ê°ì²´
        """
        # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
        if yaml_path is None:
            yaml_path = Path(__file__).parent / 'config.yaml'
        else:
            yaml_path = Path(yaml_path)
        
        # YAML íŒŒì¼ ì½ê¸°
        logger.info(f"ğŸ“„ ì„¤ì • íŒŒì¼ ë¡œë“œ: {yaml_path}")
        with open(yaml_path, 'r', encoding='utf-8') as f:
            config_dict = yaml.safe_load(f)
        
        # svd ì„¹ì…˜ ì¶”ì¶œ
        if 'svd' not in config_dict:
            raise ValueError("config.yaml íŒŒì¼ì— 'svd' ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        svd_config = config_dict['svd']
        
        # rating_scaleì´ ë¦¬ìŠ¤íŠ¸ë¡œ ë¡œë“œë˜ë¯€ë¡œ íŠœí”Œë¡œ ë³€í™˜
        if 'rating_scale' in svd_config:
            svd_config['rating_scale'] = tuple(svd_config['rating_scale'])
        
        # ë°ì´í„° í†µí•© ì„¤ì • ì¶”ì¶œ (svd ì„¹ì…˜ì—ì„œ ì§ì ‘ ì½ê¸°)
        use_integrated_data = svd_config.get('use_integrated_data', False)
        
        # ë°ì´í„° í†µí•© ì„¤ì •ì„ svd_configì— ì¶”ê°€
        svd_config.update({
            'use_integrated_data': use_integrated_data
        })
        
        logger.info("âœ… ì„¤ì • ë¡œë“œ ì™„ë£Œ")
        return cls(**svd_config)


@dataclass
class EvaluationMetrics:
    """ëª¨ë¸ í‰ê°€ ì§€í‘œ"""
    train_rmse: float
    test_rmse: float
    train_mae: float
    test_mae: float
    user_overlap: float
    item_overlap: float
    
    def __str__(self):
        return f"""
=== í‰ê°€ ê²°ê³¼ ìš”ì•½ ===
Train RMSE: {self.train_rmse:.4f}
Test RMSE:  {self.test_rmse:.4f}
Train MAE:  {self.train_mae:.4f}
Test MAE:   {self.test_mae:.4f}

User Overlap: {self.user_overlap:.2f}%
Item Overlap: {self.item_overlap:.2f}%
"""


class SVDRecommenderPipeline:
    """
    SVD ê¸°ë°˜ ì˜í™” ì¶”ì²œ ì‹œìŠ¤í…œì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸
    
    ì£¼ìš” ê¸°ëŠ¥:
    - ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
    - Train/Test ë¶„í• 
    - SVD ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
    - ì˜í™” ì¶”ì²œ
    - ëª¨ë¸ ì €ì¥/ë¡œë“œ
    """
    
    def __init__(self, config: Optional[ModelConfig] = None):
        """
        Args:
            config: ëª¨ë¸ ì„¤ì • (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        """
        self.config = config or ModelConfig()
        self.df_filtered = None
        self.df_firebase = None
        self.trained_user_ids = None
        self.svd_model = None        
        self.metrics: Optional[EvaluationMetrics] = None
        
    def predict(self, user_id:str, movie_id:str) -> float:
        """
        íŠ¹ì • ì‚¬ìš©ìì™€ ì˜í™”ì— ëŒ€í•œ í‰ì  ì˜ˆì¸¡
        
        Args:
            user_id: ì‚¬ìš©ì ID
            movie_id: ì˜í™” ID
            
        Returns:
            ì˜ˆì¸¡ëœ í‰ì  (float)
        """
        if self.svd_model is None:
            raise ValueError("ëª¨ë¸ì„ ë¨¼ì € í•™ìŠµí•´ì£¼ì„¸ìš”. run_full_pipeline() ì‹¤í–‰ í•„ìš”")
        
        prediction = self.svd_model.predict(user_id, movie_id)
        return prediction.est

    def prepare_surprise_dataset(self, df: pd.DataFrame) -> Dataset:
        """
        Surprise ë¼ì´ë¸ŒëŸ¬ë¦¬ìš© ë°ì´í„°ì…‹ ì¤€ë¹„
        
        Args:
            df: ì‚¬ìš©í•  ë°ì´í„°í”„ë ˆì„ (Noneì´ë©´ self.df_filtered ì‚¬ìš©)
            
        Returns:
            Surprise Dataset ê°ì²´
        """        
        logger.info("=== Surprise Dataset ì¤€ë¹„ ===")
        
        # Reader ê°ì²´ ìƒì„± (í‰ì  ë²”ìœ„ ì§€ì •)
        reader = Reader(rating_scale=self.config.rating_scale)
        
        # DataFrameì„ Surprise Datasetìœ¼ë¡œ ë³€í™˜
        self.surprise_data = Dataset.load_from_df(
            df[['user_id', 'movie_id', 'rating']],
            reader
        )
        
        logger.info("âœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ")
        logger.info(f"  - ì´ í‰ì  ìˆ˜: {len(df):,}")
        logger.info(f"  - í‰ì  ë²”ìœ„: {self.config.rating_scale[0]} ~ {self.config.rating_scale[1]}")
        
        return self.surprise_data
                
    def split_train_test(self, data: Dataset, firebase_data: Dataset) -> Tuple[Dataset, Dataset]:
        """
        Train/Test ë°ì´í„° ë¶„í• 
        
        Returns:
            (trainset, testset) íŠœí”Œ
        """
       
        logger.info(f"=== Train/Test Split (test_size={self.config.test_size}) ===")

        trainset, testset = train_test_split(
            data,
            test_size=self.config.test_size,
            random_state=self.config.random_state
        )

        def dataset_to_df(dataset: Dataset) -> pd.DataFrame:
            df = pd.DataFrame(dataset.raw_ratings, columns=["user_id", "movie_id", "rating", "timestamp"])
            return df.drop(columns=["timestamp"], errors="ignore")

        df_train = dataset_to_df(data)
        df_firebase = dataset_to_df(firebase_data)
        df_train_merged = pd.concat([df_train, df_firebase], ignore_index=True)
        train_dataset = self.prepare_surprise_dataset(df_train_merged)
        trainset = train_dataset.build_full_trainset()
        
        logger.info("âœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ")
        logger.info(f"  - Train set size: {trainset.n_ratings:,}")
        logger.info(f"  - Test set size: {len(testset):,}")
        logger.info("Train set í†µê³„:")
        logger.info(f"  - ì‚¬ìš©ì ìˆ˜: {trainset.n_users:,}")
        logger.info(f"  - ì˜í™” ìˆ˜: {trainset.n_items:,}")
        logger.info(f"  - í‰ì  ìˆ˜: {trainset.n_ratings:,}")
        logger.info(f"  - ì „ì²´ ì…€ ìˆ˜: {trainset.n_users * trainset.n_items:,}")
        sparsity = (1 - trainset.n_ratings / (trainset.n_users * trainset.n_items)) * 100
        logger.info(f"  - Train Sparsity: {sparsity:.2f}%")
        
        return trainset, testset
    
    def train(self, trainset: Dataset) -> SVD:
        """
        SVD ëª¨ë¸ í•™ìŠµ
        
        Returns:
            í•™ìŠµëœ SVD ëª¨ë¸
        """        
        logger.info("=== SVD ëª¨ë¸ í•™ìŠµ ===")
        
        # SVD í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶œë ¥
        logger.info("SVD íŒŒë¼ë¯¸í„°:")
        logger.info(f"  - n_factors: {self.config.n_factors}")
        logger.info(f"  - n_epochs: {self.config.n_epochs}")
        logger.info(f"  - lr_all: {self.config.lr_all}")
        logger.info(f"  - reg_all: {self.config.reg_all}")
        logger.info(f"  - random_state: {self.config.random_state}")
        logger.info(f"  - verbose: {self.config.verbose}")
        
        logger.info("í•™ìŠµ ì‹œì‘...")
        
        # SVD ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
        self.svd_model = SVD(
            n_factors=self.config.n_factors,
            n_epochs=self.config.n_epochs,
            lr_all=self.config.lr_all,
            reg_all=self.config.reg_all,
            random_state=self.config.random_state,
            verbose=self.config.verbose
        )
        
        self.svd_model.fit(trainset)
        
        logger.info("âœ… í•™ìŠµ ì™„ë£Œ!")
        
        return self.svd_model
    
    def evaluate(self, trainset: Dataset, testset: Dataset):
        """
        ëª¨ë¸ í‰ê°€ (Train/Test RMSE, MAE)
        
        Returns:
            í‰ê°€ ì§€í‘œê°€ ë‹´ê¸´ EvaluationMetrics ê°ì²´
        """
        if self.svd_model is None:
            raise ValueError("ëª¨ë¸ì„ ë¨¼ì € í•™ìŠµí•´ì£¼ì„¸ìš”. train() ì‹¤í–‰ í•„ìš”")
        
        logger.info("=== ëª¨ë¸ í‰ê°€ ===")
        
        # Test set í‰ê°€
        logger.info("Test set í‰ê°€:")
        test_predictions = self.svd_model.test(testset)
        test_rmse = accuracy.rmse(test_predictions, verbose=True)
        test_mae = accuracy.mae(test_predictions, verbose=True)
        
        # Train set í‰ê°€ (overfitting í™•ì¸ìš©)
        logger.info("Train set í‰ê°€:")
        train_testset = trainset.build_testset()
        train_predictions = self.svd_model.test(train_testset)
        train_rmse = accuracy.rmse(train_predictions, verbose=True)
        train_mae = accuracy.mae(train_predictions, verbose=True)
        
        # User-Item Overlap ê³„ì‚°
        train_users = set(trainset._raw2inner_id_users.keys())
        train_items = set(trainset._raw2inner_id_items.keys())
        test_users = set([uid for (uid, _, _) in testset])
        test_items = set([iid for (_, iid, _) in testset])
        
        user_overlap = len(train_users & test_users) / len(test_users) * 100
        item_overlap = len(train_items & test_items) / len(test_items) * 100
        
        # í‰ê°€ ì§€í‘œ ì €ì¥
        self.metrics = EvaluationMetrics(
            train_rmse=train_rmse,
            test_rmse=test_rmse,
            train_mae=train_mae,
            test_mae=test_mae,
            user_overlap=user_overlap,
            item_overlap=item_overlap
        )
        
        logger.info(str(self.metrics))
        
        # Overfitting ì²´í¬
        if test_rmse - train_rmse > 0.1:
            logger.warning("âš ï¸  ê²½ê³ : Test RMSEê°€ Train RMSEë³´ë‹¤ ìœ ì˜ë¯¸í•˜ê²Œ ë†’ìŠµë‹ˆë‹¤. Overfitting ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")
        elif test_rmse - train_rmse < 0.05:
            logger.info("âœ… Trainê³¼ Test ì„±ëŠ¥ì´ ë¹„ìŠ·í•©ë‹ˆë‹¤. ì ì ˆí•œ ì¼ë°˜í™”ê°€ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤.")
        else:
            logger.info("âœ… Trainê³¼ Test ì„±ëŠ¥ ì°¨ì´ê°€ ì ì ˆí•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
            
    def recommend_for_user(
        self,
        user_id: str,
        df_movies: pd.DataFrame,
        n: int = 10
    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        íŠ¹ì • ì‚¬ìš©ìì—ê²Œ ì˜í™” ì¶”ì²œ
        
        Args:
            user_id: ì¶”ì²œë°›ì„ ì‚¬ìš©ì ID
            df_movies: ì˜í™” ì •ë³´ ë°ì´í„°í”„ë ˆì„
            n: ì¶”ì²œí•  ì˜í™” ê°œìˆ˜
            
        Returns:
            (top_watched, recommendations) íŠœí”Œ
            - top_watched: ì‚¬ìš©ìê°€ ë†’ê²Œ í‰ê°€í•œ ì˜í™” Top N
            - recommendations: ì¶”ì²œ ì˜í™” Top N
        """
        if self.svd_model is None:
            raise ValueError("ëª¨ë¸ì„ ë¨¼ì € í•™ìŠµí•´ì£¼ì„¸ìš”. train() ì‹¤í–‰ í•„ìš”")

        if user_id not in self.trained_user_ids:
            raise ValueError(f"ì‚¬ìš©ì ID '{user_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì‚¬ìš©ìê°€ ë³¸ ì˜í™”
        user_ratings = self.df_filtered[self.df_filtered['user_id'] == user_id]
        watched_movie_ids = set(user_ratings['movie_id'])
        
        # ì‚¬ìš©ìê°€ ë³´ì§€ ì•Šì€ ì˜í™”ì— ëŒ€í•´ ì˜ˆì¸¡
        all_movie_ids = set(self.df_filtered['movie_id'].unique())
        unseen_movie_ids = all_movie_ids - watched_movie_ids
        
        predictions = []
        for movie_id in unseen_movie_ids:
            pred = self.svd_model.predict(user_id, movie_id)
            predictions.append({
                'movie_id': movie_id,
                'predicted_rating': pred.est
            })
        
        # ì¶”ì²œ ëª©ë¡ ìƒì„±
        recommendations = pd.DataFrame(predictions)
        recommendations = pd.merge(recommendations, df_movies, on='movie_id', how='left')
        recommendations = recommendations.sort_values('predicted_rating', ascending=False).head(n)
        
        # ì‚¬ìš©ìê°€ ë†’ê²Œ í‰ê°€í•œ ì˜í™”
        top_watched = user_ratings.sort_values('rating', ascending=False).head(n)
        top_watched = pd.merge(top_watched, df_movies, on='movie_id', how='left')
        
        return top_watched, recommendations
    
    def save_model(self, filepath: str):
        """
        í•™ìŠµëœ ëª¨ë¸ì„ íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            filepath: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
        """
        if self.svd_model is None:
            raise ValueError("ì €ì¥í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. train() ë¨¼ì € ì‹¤í–‰ í•„ìš”")
        
        # ì €ì¥í•  ë°ì´í„° ì¤€ë¹„
        model_data = {
            'config': self.config,
            'svd_model': self.svd_model,
            'metrics': self.metrics,
            'df_filtered': self.df_filtered,
            'trained_user_ids': self.trained_user_ids
        }
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        filepath = Path(filepath)
        filepath.parent.mkdir(parents=True, exist_ok=True)
        
        # ëª¨ë¸ ì €ì¥
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)
        
        # íŒŒì¼ í¬ê¸° ì¶œë ¥
        file_size = format_file_size(filepath)
        logger.info(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {filepath}")
        logger.info(f"ğŸ“¦ íŒŒì¼ í¬ê¸°: {file_size}")
        
    @classmethod
    def load_model(cls, filepath: str) -> 'SVDRecommenderPipeline':
        """
        ì €ì¥ëœ ëª¨ë¸ì„ ë¡œë“œ
        
        Args:
            filepath: ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ë¡œë“œëœ SVDRecommenderPipeline ê°ì²´
        """
        filepath = Path(filepath)
        
        if not filepath.exists():
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
        
        # íŒŒì¼ í¬ê¸° ì¶œë ¥
        file_size = format_file_size(filepath)
        logger.info(f"ğŸ“‚ ëª¨ë¸ ë¡œë“œ ì¤‘: {filepath}")
        logger.info(f"ğŸ“¦ íŒŒì¼ í¬ê¸°: {file_size}")
        
        # pickle íŒŒì¼ì˜ ëª¨ë“ˆ ê²½ë¡œ í˜¸í™˜ì„±ì„ ìœ„í•œ alias ì¶”ê°€
        import sys
        import modeling.models.svd as svd_module
        import modeling.models.item_based as item_based_module
        sys.modules['models.svd'] = svd_module
        sys.modules['models.item_based'] = item_based_module
        sys.modules['models'] = sys.modules['modeling.models']
        
        with open(filepath, 'rb') as f:
            model_data = pickle.load(f)
        
        # íŒŒì´í”„ë¼ì¸ ê°ì²´ ìƒì„±
        pipeline = cls(config=model_data['config'])
        pipeline.svd_model = model_data['svd_model']
        pipeline.metrics = model_data.get('metrics', None)
        pipeline.df_filtered = model_data.get('df_filtered', None)
        pipeline.trained_user_ids = model_data.get('trained_user_ids', [])
        
        logger.info("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        if pipeline.metrics:
            logger.info(f"  - Test RMSE: {pipeline.metrics.test_rmse:.4f}")
            logger.info(f"  - Test MAE: {pipeline.metrics.test_mae:.4f}")
        
        return pipeline
    
    def run_full_pipeline(self, filtered_data: pd.DataFrame, firebase_data: pd.DataFrame):
        """
        ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë°ì´í„° ë¡œë”© -> ì „ì²˜ë¦¬ -> í•™ìŠµ -> í‰ê°€)
        
        Args:
            data_path: ë°ì´í„° ê²½ë¡œ
            
        Returns:
            í‰ê°€ ì§€í‘œ
        """
        logger.info("ğŸš€ SVD ì¶”ì²œ ì‹œìŠ¤í…œ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        logger.info("=" * 60)

        self.df_filtered = filtered_data
        self.df_firebase = firebase_data
        
        trained_user_ids = []
        trained_user_ids.extend(filtered_data['user_id'].values.tolist())
        trained_user_ids.extend(firebase_data['user_id'].values.tolist())

        self.trained_user_ids = trained_user_ids

        filtered_data, firebase_data = self.prepare_surprise_dataset(filtered_data), self.prepare_surprise_dataset(firebase_data)

        trainset, testset = self.split_train_test(data=filtered_data, firebase_data=firebase_data)
        
        # 5. ëª¨ë¸ í•™ìŠµ
        self.train(trainset)
        
        # 6. ëª¨ë¸ í‰ê°€
        self.evaluate(trainset, testset)
        
        logger.info("=" * 60)
        logger.info("âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")

# ê°„ë‹¨í•œ ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # Logger ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # ëª¨ë¸ ì„¤ì •
    config = ModelConfig(
        n_factors=50,
        n_epochs=20,
        lr_all=0.005,
        reg_all=0.02,
        test_size=0.2,
        min_user_ratings=30,
        min_movie_ratings=10,
        verbose=True
    )
    
    # íŒŒì´í”„ë¼ì¸ ìƒì„± ë° ì‹¤í–‰
    pipeline = SVDRecommenderPipeline(config)
    metrics = pipeline.run_full_pipeline()
    
    # ëª¨ë¸ ì €ì¥
    model_path = Path(__file__).parent / 'pkls' / 'svd_model.pkl'
    pipeline.save_model(str(model_path))
    
    # ì˜í™” ë°ì´í„° ë¡œë“œ ë° ì¶”ì²œ
    df_movies = load_movie_data()
    
    # íŠ¹ì • ì‚¬ìš©ìì—ê²Œ ì¶”ì²œ
    user_id = pipeline.df_filtered['user_id'].iloc[0]
    top_watched, recommendations = pipeline.recommend_for_user(user_id, df_movies, n=5)
    
    logger.info("ğŸ¬ ìì£¼ ë³¸ ì˜í™” (ë‚´ê°€ ì§ì ‘ ë³¸ ì˜í™” ì¤‘ í‰ì  ìƒìœ„):")
    logger.info("\n" + top_watched[['movie_title', 'rating', 'title']].to_string(index=False))
    
    logger.info("âœ¨ ì¶”ì²œ ì˜í™” (ì•„ì§ ì•ˆ ë³¸ ì˜í™” ì¤‘ ì˜ˆìƒ í‰ì ì´ ë†’ì€ ìˆœ):")
    logger.info("\n" + recommendations[['title', 'predicted_rating', 'genre', 'year']].to_string(index=False))
