"""
Item-Based Collaborative Filtering ì˜í™” ì¶”ì²œ ì‹œìŠ¤í…œ íŒŒì´í”„ë¼ì¸
"""
import pickle
import logging
import time
import yaml
from pathlib import Path
from typing import Optional
from dataclasses import dataclass

import numpy as np
import pandas as pd
from scipy.sparse import csr_matrix, lil_matrix
from sklearn.metrics.pairwise import cosine_similarity

import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from data_scraping.common.data_loader import load_ratings_data, load_movie_data
from modeling.utils.data import filter_by_min_counts, preprocess_id_mapping
from modeling.utils.file_utils import format_file_size

# Logger ì„¤ì •
logger = logging.getLogger(__name__)


@dataclass
class ItemBasedConfig:
    """Item-Based ëª¨ë¸ ì„¤ì •"""
    min_user_ratings: int = 30
    min_movie_ratings: int = 10
    top_k: int = 50  # ê° ì˜í™”ë‹¹ ìœ ì§€í•  ìƒìœ„ Kê°œì˜ ìœ ì‚¬ ì˜í™”
    verbose: bool = True
    
    def __str__(self):
        return f"""
=== Item-Based CF ì„¤ì • ===
ìµœì†Œ ì‚¬ìš©ì í‰ì  ìˆ˜: {self.min_user_ratings}
ìµœì†Œ ì˜í™” í‰ì  ìˆ˜: {self.min_movie_ratings}
Top-K ìœ ì‚¬ë„: {self.top_k}
"""
    
    @classmethod
    def from_yaml(cls, yaml_path: Optional[str] = None) -> 'ItemBasedConfig':
        """
        YAML íŒŒì¼ì—ì„œ ì„¤ì •ì„ ë¡œë“œí•˜ì—¬ ItemBasedConfig ê°ì²´ ìƒì„±
        
        Args:
            yaml_path: YAML íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©)
            
        Returns:
            ItemBasedConfig ê°ì²´
        """
        # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
        if yaml_path is None:
            yaml_path = Path(__file__).parent / 'config.yaml'
        else:
            yaml_path = Path(yaml_path)
        
        # YAML íŒŒì¼ ì½ê¸°
        logger.info(f"ğŸ“„ ì„¤ì • íŒŒì¼ ë¡œë“œ: {yaml_path}")
        with open(yaml_path, 'r', encoding='utf-8') as f:
            config_dict = yaml.safe_load(f)
        
        # item_based ì„¹ì…˜ ì¶”ì¶œ
        if 'item_based' not in config_dict:
            raise ValueError("config.yaml íŒŒì¼ì— 'item_based' ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        item_based_config = config_dict['item_based']
        
        logger.info("âœ… ì„¤ì • ë¡œë“œ ì™„ë£Œ")
        return cls(**item_based_config)


class ItemBasedRecommender:
    """
    Item-Based Collaborative Filtering ì¶”ì²œ ì‹œìŠ¤í…œ
    
    ì£¼ìš” ê¸°ëŠ¥:
    - ì•„ì´í…œ ê°„ ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚° (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
    - Top-K ìœ ì‚¬ë„ ìµœì í™” (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
    - ìœ ì‚¬í•œ ì˜í™” ì¶”ì²œ
    - ëª¨ë¸ ì €ì¥/ë¡œë“œ
    """
    
    def __init__(self, config: Optional[ItemBasedConfig] = None):
        """
        Args:
            config: ëª¨ë¸ ì„¤ì • (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        """
        self.config = config or ItemBasedConfig()
        self.item_similarity_matrix = None
        self.id_mapping = None
        self.df_mapped = None
        self.n_users = None
        self.n_movies = None
        
        if self.config.verbose:
            logger.info("âœ… ItemBasedRecommender ì´ˆê¸°í™” ì™„ë£Œ")
            logger.info(str(self.config))
    
    def fit(self, df_ratings: Optional[pd.DataFrame] = None):
        """
        í•™ìŠµ ë°ì´í„°ë¡œ ì•„ì´í…œ ìœ ì‚¬ë„ í–‰ë ¬ ìƒì„±
        
        Args:
            df_ratings: í‰ì  ë°ì´í„°í”„ë ˆì„ (Noneì´ë©´ ìë™ ë¡œë“œ)
        """
        logger.info("\n" + "="*50)
        logger.info("ğŸ“Š Item-Based CF í•™ìŠµ ì‹œì‘")
        logger.info("="*50)
        
        # 1. ë°ì´í„° ë¡œë”©
        if df_ratings is None:
            logger.info("\n[1/4] ë°ì´í„° ë¡œë”© ì¤‘...")
            df_ratings = load_ratings_data()
        
        # 2. ë°ì´í„° í•„í„°ë§
        logger.info("\n[2/4] ë°ì´í„° í•„í„°ë§ ì¤‘...")
        df_filtered = filter_by_min_counts(
            df_ratings,
            min_user_ratings=self.config.min_user_ratings,
            min_movie_ratings=self.config.min_movie_ratings,
            verbose=self.config.verbose
        )
        
        # 3. ID ë§¤í•‘
        logger.info("\n[3/4] ID ë§¤í•‘ ì¤‘...")
        self.df_mapped, self.id_mapping = preprocess_id_mapping(
            df_filtered,
            verbose=self.config.verbose
        )
        
        self.n_users = self.df_mapped['user_idx'].nunique()
        self.n_movies = self.df_mapped['movie_idx'].nunique()
        
        # 4. ìœ ì‚¬ë„ í–‰ë ¬ ìƒì„±
        logger.info("\n[4/4] ì•„ì´í…œ ìœ ì‚¬ë„ í–‰ë ¬ ìƒì„± ì¤‘...")
        self._build_similarity_matrix()
        
        logger.info("\n" + "="*50)
        logger.info("âœ… í•™ìŠµ ì™„ë£Œ!")
        logger.info("="*50)
    
    def _build_similarity_matrix(self):
        """ì•„ì´í…œ ê°„ ìœ ì‚¬ë„ í–‰ë ¬ ìƒì„±"""
        logger.info(f"ì‚¬ìš©ì-ì•„ì´í…œ í–‰ë ¬ ìƒì„± ì¤‘... ({self.n_users} x {self.n_movies})")
        
        # User-Item í–‰ë ¬ ìƒì„± (Sparse Matrix)
        user_item_matrix = csr_matrix(
            (
                self.df_mapped['rating'].values,
                (self.df_mapped['user_idx'].values, self.df_mapped['movie_idx'].values)
            ),
            shape=(self.n_users, self.n_movies)
        )
        
        # Item-User í–‰ë ¬ (ì „ì¹˜)
        item_user_matrix = user_item_matrix.T
        
        logger.info("ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘...")
        start_time = time.time()
        
        # ì•„ì´í…œ ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        item_similarity = cosine_similarity(item_user_matrix, dense_output=False)
        
        elapsed = time.time() - start_time
        logger.info(f"âœ… ìœ ì‚¬ë„ ê³„ì‚° ì™„ë£Œ (ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ)")
        
        # Top-K ìµœì í™”
        self.item_similarity_matrix = self._build_topk_similarity(
            item_similarity,
            k=self.config.top_k
        )
    
    def _build_topk_similarity(self, similarity_matrix, k: int):
        """
        Top-K ìœ ì‚¬ë„ í–‰ë ¬ ìƒì„± (ë©”ëª¨ë¦¬ ìµœì í™”)
        
        Args:
            similarity_matrix: ì „ì²´ ìœ ì‚¬ë„ í–‰ë ¬ (sparse matrix)
            k: ê° ì•„ì´í…œë‹¹ ìœ ì§€í•  ìƒìœ„ Kê°œ
        
        Returns:
            Top-Kë§Œ í¬í•¨í•˜ëŠ” sparse matrix
        """
        # ë³€í™˜ ì „ í¬ê¸° ì¶œë ¥
        original_memory = similarity_matrix.data.nbytes / (1024**2)
        original_nnz = similarity_matrix.nnz
        
        if self.config.verbose:
            logger.info("\n=== ë³€í™˜ ì „ í¬ê¸° ===")
            logger.info(f"  Non-zero ìš”ì†Œ ìˆ˜: {original_nnz:,}")
            logger.info(f"  ë©”ëª¨ë¦¬ í¬ê¸°: {original_memory:.2f} MB")
            logger.info(f"  í–‰ë ¬ í¬ê¸°: {similarity_matrix.shape}")
        
        n_items = similarity_matrix.shape[0]
        topk_similarity = lil_matrix(similarity_matrix.shape)
        
        logger.info(f"\nTop-{k} ìœ ì‚¬ë„ í–‰ë ¬ ìƒì„± ì¤‘...")
        start_time = time.time()
        
        for i in range(n_items):
            if i % 1000 == 0 and self.config.verbose:
                logger.info(f"  ì§„í–‰: {i}/{n_items} ({100*i/n_items:.1f}%)")
            
            row = similarity_matrix.getrow(i).toarray().flatten()
            row[i] = -1  # ìê¸° ìì‹  ì œì™¸
            
            # Top-K ì„ íƒ
            if len(row) > k:
                top_k_indices = np.argpartition(row, -k)[-k:]
                top_k_indices = top_k_indices[row[top_k_indices] > 0]
            else:
                top_k_indices = np.where(row > 0)[0]
            
            if len(top_k_indices) > 0:
                topk_similarity[i, top_k_indices] = row[top_k_indices]
        
        elapsed_time = time.time() - start_time
        logger.info(f"âœ… ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
        
        # CSRë¡œ ë³€í™˜
        topk_similarity_csr = topk_similarity.tocsr()
        
        # ë³€í™˜ í›„ í¬ê¸° ì¶œë ¥
        if self.config.verbose:
            optimized_memory = topk_similarity_csr.data.nbytes / (1024**2)
            optimized_nnz = topk_similarity_csr.nnz
            logger.info("\n=== ë³€í™˜ í›„ í¬ê¸° ===")
            logger.info(f"  Non-zero ìš”ì†Œ ìˆ˜: {optimized_nnz:,}")
            logger.info(f"  ë©”ëª¨ë¦¬ í¬ê¸°: {optimized_memory:.2f} MB")
            logger.info(f"  í–‰ë ¬ í¬ê¸°: {topk_similarity_csr.shape}")
            
            # ì ˆê°ë¥  ì¶œë ¥
            memory_reduction = (1 - optimized_memory / original_memory) * 100
            nnz_reduction = (1 - optimized_nnz / original_nnz) * 100
            logger.info("\n=== ìµœì í™” íš¨ê³¼ ===")
            logger.info(f"  ë©”ëª¨ë¦¬ ì ˆê°ë¥ : {memory_reduction:.2f}%")
            logger.info(f"  Non-zero ìš”ì†Œ ê°ì†Œìœ¨: {nnz_reduction:.2f}%")
        
        return topk_similarity_csr
    
    def recommend(
        self,
        movie_id: str,
        top_n: int = 10,
        return_scores: bool = False
    ) -> pd.DataFrame:
        """
        íŠ¹ì • ì˜í™”ì™€ ìœ ì‚¬í•œ ì˜í™” ì¶”ì²œ
        
        Args:
            movie_id: ì˜í™” ID
            top_n: ì¶”ì²œí•  ì˜í™” ê°œìˆ˜
            return_scores: ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨ ì—¬ë¶€
        
        Returns:
            ì¶”ì²œ ì˜í™” ì •ë³´ DataFrame
        """
        if self.item_similarity_matrix is None:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. fit()ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        # movie_idë¥¼ movie_idxë¡œ ë³€í™˜
        if movie_id not in self.id_mapping.movie_to_idx:
            logger.warning(f"âŒ ì˜í™” ID '{movie_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        movie_idx = self.id_mapping.movie_to_idx[movie_id]
        
        # ìœ ì‚¬ë„ ì¶”ì¶œ
        similarities = self.item_similarity_matrix[movie_idx].toarray().flatten()
        
        # ìœ ì‚¬ë„ê°€ 0ë³´ë‹¤ í° ì˜í™”ë“¤ë§Œ ì„ íƒ (ìê¸° ìì‹  ì œì™¸)
        similar_items = []
        for idx, sim in enumerate(similarities):
            if idx != movie_idx and sim > 0:
                similar_items.append((idx, sim))
        
        # ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ìˆœ)
        similar_items.sort(key=lambda x: x[1], reverse=True)
        
        # Top-N ì„ íƒ
        top_similar = similar_items[:top_n]
        
        if len(top_similar) == 0:
            logger.warning("\nâš ï¸ ìœ ì‚¬í•œ ì˜í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ì˜í™” IDì™€ ìœ ì‚¬ë„ ì ìˆ˜ ì¶”ì¶œ
        movie_indices = [idx for idx, _ in top_similar]
        scores = [score for _, score in top_similar]
        recommended_movie_ids = [self.id_mapping.idx_to_movie[idx] for idx in movie_indices]
        
        # ì˜í™” ì •ë³´ ë¡œë“œ
        movie_df = load_movie_data()
        result_df = movie_df[movie_df['movie_id'].isin(recommended_movie_ids)].copy()
        
        # ìœ ì‚¬ë„ ì ìˆ˜ ì¶”ê°€
        if return_scores:
            score_dict = dict(zip(recommended_movie_ids, scores))
            result_df['similarity_score'] = result_df['movie_id'].map(score_dict)
            # ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            result_df = result_df.sort_values('similarity_score', ascending=False)
        
        return result_df.reset_index(drop=True)
    
    def recommend_by_title(
        self,
        movie_title: str,
        top_n: int = 10,
        return_scores: bool = False
    ) -> pd.DataFrame:
        """
        ì˜í™” ì œëª©ìœ¼ë¡œ ìœ ì‚¬í•œ ì˜í™” ì¶”ì²œ
        
        Args:
            movie_title: ì˜í™” ì œëª©
            top_n: ì¶”ì²œí•  ì˜í™” ê°œìˆ˜
            return_scores: ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨ ì—¬ë¶€
        
        Returns:
            ì¶”ì²œ ì˜í™” ì •ë³´ DataFrame
        """
        # ì˜í™” ì œëª©ìœ¼ë¡œ ID ì°¾ê¸°
        from modeling.utils.data import find_movie_id_by_title
        
        movie_df = load_movie_data()
        searched_df = find_movie_id_by_title(movie_title, self.df_mapped)
        
        if searched_df is None or len(searched_df) == 0:
            logger.warning(f"âŒ ì˜í™” '{movie_title}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ì—¬ëŸ¬ ê°œ ê²€ìƒ‰ë˜ë©´ ì²« ë²ˆì§¸ ì„ íƒ
        if len(searched_df) > 1:
            logger.warning("âš ï¸ ì—¬ëŸ¬ ì˜í™”ê°€ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ì˜í™”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            searched_df = pd.merge(searched_df, movie_df, on='movie_id', how='left')
            logger.info("\nê²€ìƒ‰ëœ ì˜í™”ë“¤:")
            logger.info(searched_df[['movie_id', 'movie_title']].to_string(index=False))
        
        movie_id = searched_df.iloc[0]['movie_id']
        logger.info(f"\nì„ íƒëœ ì˜í™”: {movie_id}")
        
        return self.recommend(movie_id, top_n, return_scores)
    
    def save(self, filepath: str):
        """
        í•™ìŠµëœ ëª¨ë¸ ì €ì¥
        
        Args:
            filepath: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ (.pkl)
        """
        if self.item_similarity_matrix is None:
            raise ValueError("ì €ì¥í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. fit()ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        filepath = Path(filepath)
        filepath.parent.mkdir(parents=True, exist_ok=True)
        
        model_data = {
            'config': self.config,
            'item_similarity_matrix': self.item_similarity_matrix,
            'id_mapping': self.id_mapping,
            'df_mapped': self.df_mapped,
            'n_users': self.n_users,
            'n_movies': self.n_movies
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)
        
        # íŒŒì¼ í¬ê¸° ì¶œë ¥
        file_size = format_file_size(filepath)
        logger.info(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {filepath}")
        logger.info(f"ğŸ“¦ íŒŒì¼ í¬ê¸°: {file_size}")
    
    @classmethod
    def load(cls, filepath: str) -> 'ItemBasedRecommender':
        """
        ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ
        
        Args:
            filepath: ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ (.pkl)
        
        Returns:
            ItemBasedRecommender ê°ì²´
        """
        filepath = Path(filepath)
        
        if not filepath.exists():
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
        
        # íŒŒì¼ í¬ê¸° ì¶œë ¥
        file_size = format_file_size(filepath)
        logger.info(f"ğŸ“‚ ëª¨ë¸ ë¡œë“œ ì¤‘: {filepath}")
        logger.info(f"ğŸ“¦ íŒŒì¼ í¬ê¸°: {file_size}")
        
        # pickle íŒŒì¼ì˜ ëª¨ë“ˆ ê²½ë¡œ í˜¸í™˜ì„±ì„ ìœ„í•œ alias ì¶”ê°€
        import sys
        import modeling.models.svd as svd_module
        import modeling.models.item_based as item_based_module
        sys.modules['models.svd'] = svd_module
        sys.modules['models.item_based'] = item_based_module
        sys.modules['models'] = sys.modules['modeling.models']
        
        with open(filepath, 'rb') as f:
            model_data = pickle.load(f)
        
        # ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        recommender = cls(config=model_data['config'])
        recommender.item_similarity_matrix = model_data['item_similarity_matrix']
        recommender.id_mapping = model_data.get('id_mapping', None)
        recommender.df_mapped = model_data.get('df_mapped', None)
        recommender.n_users = model_data.get('n_users', None)
        recommender.n_movies = model_data.get('n_movies', None)
        
        logger.info("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        return recommender


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(message)s'
    )
    
    # 1. YAML íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ
    config = ItemBasedConfig.from_yaml()
    
    # 2. ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° í•™ìŠµ
    recommender = ItemBasedRecommender(config=config)
    recommender.fit()
    
    # 3. ì˜í™” ì¶”ì²œ
    print("\n" + "="*50)
    print("ğŸ¬ ì˜í™” ì¶”ì²œ í…ŒìŠ¤íŠ¸")
    print("="*50)
    
    # ì˜í™” ì œëª©ìœ¼ë¡œ ì¶”ì²œ
    movie_title = "ê¸°ìƒì¶©"
    print(f"\n'{movie_title}'ì™€ ìœ ì‚¬í•œ ì˜í™” ì¶”ì²œ:")
    recommendations = recommender.recommend_by_title(
        movie_title,
        top_n=10,
        return_scores=True
    )
    
    if recommendations is not None:
        display_cols = ['movie_id', 'movie_title', 'similarity_score']
        print(recommendations[display_cols].to_string(index=False))
    
    # 4. ëª¨ë¸ ì €ì¥
    save_path = Path(__file__).parent / 'pkls' / 'trained_item_based.pkl'
    recommender.save(save_path)
    
    # 5. ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
    print("\n" + "="*50)
    print("ğŸ“‚ ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸")
    print("="*50)
    loaded_recommender = ItemBasedRecommender.load(save_path)
    
    # ë¡œë“œëœ ëª¨ë¸ë¡œ ì¶”ì²œ
    print(f"\n'{movie_title}'ì™€ ìœ ì‚¬í•œ ì˜í™” ì¶”ì²œ (ë¡œë“œëœ ëª¨ë¸):")
    recommendations = loaded_recommender.recommend_by_title(
        movie_title,
        top_n=5,
        return_scores=True
    )
    
    if recommendations is not None:
        display_cols = ['movie_id', 'movie_title', 'similarity_score']
        print(recommendations[display_cols].to_string(index=False))